{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c665168",
   "metadata": {},
   "source": [
    "# Building Effective Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a3b4a",
   "metadata": {},
   "source": [
    "This is based on [this article](https://www.anthropic.com/engineering/building-effective-agents) by [Anthropic](https://www.anthropic.com/). We will explore common patterns for building effective LLM agentic systems using pure Python around LLM APIs. In particular, we use the [Python SDK](https://github.com/openai/openai-python/tree/main) for the [OpenAI API](https://platform.openai.com/docs/api-reference/introduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ab857",
   "metadata": {},
   "source": [
    "## OpenAI API client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339c546",
   "metadata": {},
   "source": [
    "First, we need to load the API key in the environmental variables. The client expects the variable name `OPENAI_API_KEY` which we load from the `.env` file. This is easy to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bfff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def load_dotenv(verbose=False):\n",
      "    with open(\".env\") as f:\n",
      "        for line in f.readlines():\n",
      "            k, v = line.split(\"=\")\n",
      "            os.environ[k] = v.strip().strip('\"')\n",
      "            if verbose:\n",
      "                print(f\"Loaded env variable: {k}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from notebooks.utils import load_dotenv\n",
    "print(inspect.getsource(load_dotenv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d77b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env variable: OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f34dc",
   "metadata": {},
   "source": [
    "Then the API key is automatically read by the **client**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424d6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You're a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about the history of GPT in a single paragraph.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_text = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd2ad0",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "We can have **multiple completions** of the same prompt. This allows choosing between the responses.\n",
    "For example, we can set `temperature=0.9` to get more varied outputs, so that choosing becomes nontrivial. \n",
    "By default only 1 completion by default, hence `[0]`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f4a310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generative Pre-trained Transformer (GPT) is a series of language models '\n",
      " 'developed by OpenAI, beginning with the release of GPT-1 in 2018. GPT-1 '\n",
      " 'introduced the concept of pre-training a transformer model on a large corpus '\n",
      " 'of text before fine-tuning it on specific tasks. This approach demonstrated '\n",
      " 'significant improvements in natural language processing tasks. GPT-2, '\n",
      " 'released in 2019, scaled up the model significantly, boasting 1.5 billion '\n",
      " 'parameters and showcasing impressive text generation capabilities. Due to '\n",
      " 'concerns about misuse, OpenAI initially withheld its full release. GPT-3, '\n",
      " 'released in 2020, further scaled the model to 175 billion parameters, '\n",
      " 'becoming notable for its ability to generate human-like text across diverse '\n",
      " 'tasks with minimal prompt input. The series continued to evolve with '\n",
      " 'advancements like GPT-3.5 and ChatGPT, which improved interaction '\n",
      " 'capabilities. In 2023, GPT-4 was released, offering enhanced performance, '\n",
      " 'better understanding, and improved reasoning abilities.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda6e7b",
   "metadata": {},
   "source": [
    "Entire model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55f61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'annotations': [],\n",
      "                          'audio': None,\n",
      "                          'content': 'Generative Pre-trained Transformer (GPT) '\n",
      "                                     'is a series of language models developed '\n",
      "                                     'by OpenAI, beginning with the release of '\n",
      "                                     'GPT-1 in 2018. GPT-1 introduced the '\n",
      "                                     'concept of pre-training a transformer '\n",
      "                                     'model on a large corpus of text before '\n",
      "                                     'fine-tuning it on specific tasks. This '\n",
      "                                     'approach demonstrated significant '\n",
      "                                     'improvements in natural language '\n",
      "                                     'processing tasks. GPT-2, released in '\n",
      "                                     '2019, scaled up the model significantly, '\n",
      "                                     'boasting 1.5 billion parameters and '\n",
      "                                     'showcasing impressive text generation '\n",
      "                                     'capabilities. Due to concerns about '\n",
      "                                     'misuse, OpenAI initially withheld its '\n",
      "                                     'full release. GPT-3, released in 2020, '\n",
      "                                     'further scaled the model to 175 billion '\n",
      "                                     'parameters, becoming notable for its '\n",
      "                                     'ability to generate human-like text '\n",
      "                                     'across diverse tasks with minimal prompt '\n",
      "                                     'input. The series continued to evolve '\n",
      "                                     'with advancements like GPT-3.5 and '\n",
      "                                     'ChatGPT, which improved interaction '\n",
      "                                     'capabilities. In 2023, GPT-4 was '\n",
      "                                     'released, offering enhanced performance, '\n",
      "                                     'better understanding, and improved '\n",
      "                                     'reasoning abilities.',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1755966140,\n",
      " 'id': 'chatcmpl-C7lISIh7GAcohRqN1NOQ1uLilfL2i',\n",
      " 'model': 'gpt-4o-2024-08-06',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_80956533cb',\n",
      " 'usage': {'completion_tokens': 197,\n",
      "           'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                         'audio_tokens': 0,\n",
      "                                         'reasoning_tokens': 0,\n",
      "                                         'rejected_prediction_tokens': 0},\n",
      "           'prompt_tokens': 28,\n",
      "           'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
      "           'total_tokens': 225}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff814f09",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "We are using the **chat completions** API where an autoregressive process that's running under the hood. Here the prompt to be completed is:\n",
    "\n",
    "```python\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic but terse assistant.\"},   # prompt\n",
    "    {\"role\": \"user\", \"content\": \"What is the color of the sky?\"}              # prompt\n",
    "]\n",
    "```\n",
    "\n",
    "And the completion is given by the API's output:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"content\": \"The sky's color shifts from azure to amber, a canvas for sun's daily journey.\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Remark.** The generated response is statistically the most likely continuation of the prompt text sequence.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c766d",
   "metadata": {},
   "source": [
    "## Structured outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52597344",
   "metadata": {},
   "source": [
    "[Structured outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses) is a feature that ensures that a model generates responses that adhere to a supplied **schema** (e.g. a Pydantic model). As such, the output can then be parsed using the same Pydantic model. Structured outputs makes prompting significantly simpler: no more need for strongly worded prompts to achieve consistent formatting, no explicitly having to retry incorrectly formatted responses, or having invalid hallucinated values (can specify **enums**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70811ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc0da2",
   "metadata": {},
   "source": [
    "## Building block: The augmented LLM\n",
    "\n",
    "This is the foundational building block of agentic systems. The **augmented LLM** is a language model enhanced with **retrieval**, **tools**, and **memory**. Current models, due to their reasoning and understanding capabilities, are able to effectively generate their own search queries, select appropriate tools, and determinine what information to retain to solve problems or perform tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d73ec",
   "metadata": {},
   "source": [
    "![**Augmented LLM.** Attaching retrieval, tools, and memory capabilities to the LLM.](../img/augmented-llm.png){#fig-augmentedllm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac42bc",
   "metadata": {},
   "source": [
    "### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9f2f8",
   "metadata": {},
   "source": [
    "The following is a naive example that demonstrates an agent deciding whether or not to **write** to a file that represents its **long-term memory**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8117c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "    tag: str\n",
    "    info: str\n",
    "    reason: str\n",
    "\n",
    "class RetainResponse(BaseModel):\n",
    "    items: List[MemoryItem]\n",
    "\n",
    "\n",
    "class MemoryFile:\n",
    "    def __init__(self, path=\"agent_memory.json\"):\n",
    "        \"\"\"Load memory from JSON file in local path.\"\"\"\n",
    "        self.path = path\n",
    "        self.data = None\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            self.data = json.load(open(self.path))\n",
    "        except FileNotFoundError:\n",
    "            self.reset()\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.path, \"w\") as f:\n",
    "            json.dump(self.data, f, indent=2)\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = []\n",
    "        self.save()\n",
    "    \n",
    "    def add(self, item: dict[str, str]):\n",
    "        self.data.append(item)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.data)\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "mem = MemoryFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a79910c",
   "metadata": {},
   "source": [
    "The agent reads the *entire* memory and decides what information to remember from the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed52c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(user_input):\n",
    "    system_prompt = (\n",
    "        f\"You have access to a memory store: {mem} for single user. \"\n",
    "        \"Decide what new information should be remembered. Atomic facts are good. \"\n",
    "        \"NOTE: The `tag` should not be overly specific. It should be widely applicable. Follow <snake_case>. \"\n",
    "        \"NOTE: Reuse existing tags when applicable. Minimize number of unique tags. \"\n",
    "        \"NOTE: The `info` should compress information from input. Try to be concise. \"\n",
    "        \"NOTE: Zero or multiple items can be retained from a single input. \"\n",
    "        \"NOTE: Each item is added to a global memory list. There should be minimal dependence between memory items.\"\n",
    "    )\n",
    "    \n",
    "    completion = client.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=RetainResponse,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "\n",
    "def action(user_input: str) -> RetainResponse:\n",
    "    \"\"\"Store key-value pair obtained from input text to memory.\"\"\"\n",
    "    response = agent(user_input)\n",
    "\n",
    "    for item in response.items:\n",
    "        mem.add({item.tag: item.info})\n",
    "        mem.save()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee1ecb",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "The agent only expresses the intent to write to a file via the structured output. It is up to the main program to perform the actual writing to disk. This allows further [guardrails](https://cookbook.openai.com/examples/how_to_use_guardrails) to be implemented.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a448a8",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb83cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs = [\n",
    "    \"Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.\",\n",
    "    \"Traffic was smooth, arrived at work earlier than usual.\",\n",
    "    \"Took the train, had to stand the whole ride since it was packed.\",\n",
    "    \"Stopped by the bakery on the way and picked up bread for the team.\",\n",
    "    \"Opened my email first thing at the office, mostly routine messages.\",\n",
    "    \"Woah! Some guy just came out of nowhere and darted into traffic. That was pretty shocking. Crazy.\",\n",
    "    \"Listened to a podcast while walking to the subway.\",\n",
    "    \"Grabbed a pen from my desk drawer because mine ran out of ink.\",\n",
    "]\n",
    "\n",
    "memory_items = sum([[d.model_dump() for d in action(input_text).items] for input_text in logs], [])\n",
    "df_resp = pd.DataFrame(memory_items)\n",
    "mem.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf215cb",
   "metadata": {},
   "source": [
    "The agent decides whether to reuse a tag or create a new one based on its memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b45514b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: (7/9)\n",
      "['morning_routine',\n",
      " 'breakfast_choice',\n",
      " 'commute_observation',\n",
      " 'email_morning_routine',\n",
      " 'unexpected_incident',\n",
      " 'commute_habit',\n",
      " 'stationery_action']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morning_routine</td>\n",
       "      <td>User usually showers and leaves for work at the same time.</td>\n",
       "      <td>This information highlights a consistent morning routine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breakfast_choice</td>\n",
       "      <td>User had toast for breakfast.</td>\n",
       "      <td>This offers insight into typical breakfast choices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commute_observation</td>\n",
       "      <td>User arrived at work earlier than usual due to smooth traffic.</td>\n",
       "      <td>This information provides insight into the User's commute experience and may relate to the User's routine or schedule.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commute_observation</td>\n",
       "      <td>User took the train and had to stand due to packed ride.</td>\n",
       "      <td>Details about the user's commute experience, including the mode of transport and crowd conditions, are useful for understanding daily travel habits and challenges.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commute_observation</td>\n",
       "      <td>User stopped by bakery for bread for the team.</td>\n",
       "      <td>This builds on the user's commuting habits and provides insight into a possible routine or occasional activity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>email_morning_routine</td>\n",
       "      <td>User opens email first thing at office mainly for routine messages.</td>\n",
       "      <td>It captures a consistent behavior regarding email checking at the office.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unexpected_incident</td>\n",
       "      <td>User witnessed someone darting into traffic, found it shocking.</td>\n",
       "      <td>It captures a notable event that might influence the user's perception or behavior in similar situations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>commute_habit</td>\n",
       "      <td>User listens to a podcast while walking to the subway.</td>\n",
       "      <td>This provides insights into how the user spends their commute time and audio preferences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stationery_action</td>\n",
       "      <td>User grabbed a pen from desk drawer as the current one ran out of ink.</td>\n",
       "      <td>This is a routine action related to desk management and resource use.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tag  \\\n",
       "0        morning_routine   \n",
       "1       breakfast_choice   \n",
       "2    commute_observation   \n",
       "3    commute_observation   \n",
       "4    commute_observation   \n",
       "5  email_morning_routine   \n",
       "6    unexpected_incident   \n",
       "7          commute_habit   \n",
       "8      stationery_action   \n",
       "\n",
       "                                                                     info  \\\n",
       "0              User usually showers and leaves for work at the same time.   \n",
       "1                                           User had toast for breakfast.   \n",
       "2          User arrived at work earlier than usual due to smooth traffic.   \n",
       "3                User took the train and had to stand due to packed ride.   \n",
       "4                          User stopped by bakery for bread for the team.   \n",
       "5     User opens email first thing at office mainly for routine messages.   \n",
       "6         User witnessed someone darting into traffic, found it shocking.   \n",
       "7                  User listens to a podcast while walking to the subway.   \n",
       "8  User grabbed a pen from desk drawer as the current one ran out of ink.   \n",
       "\n",
       "                                                                                                                                                                reason  \n",
       "0                                                                                                            This information highlights a consistent morning routine.  \n",
       "1                                                                                                                  This offers insight into typical breakfast choices.  \n",
       "2                                               This information provides insight into the User's commute experience and may relate to the User's routine or schedule.  \n",
       "3  Details about the user's commute experience, including the mode of transport and crowd conditions, are useful for understanding daily travel habits and challenges.  \n",
       "4                                                      This builds on the user's commuting habits and provides insight into a possible routine or occasional activity.  \n",
       "5                                                                                            It captures a consistent behavior regarding email checking at the office.  \n",
       "6                                                            It captures a notable event that might influence the user's perception or behavior in similar situations.  \n",
       "7                                                                            This provides insights into how the user spends their commute time and audio preferences.  \n",
       "8                                                                                                This is a routine action related to desk management and resource use.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"tags:\", f\"({len(df_resp.tag.unique())}/{len(df_resp)})\")\n",
    "pprint(list(df_resp.tag.unique()))\n",
    "df_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98448acb",
   "metadata": {},
   "source": [
    "### Tool calling\n",
    "\n",
    "Also known as **function calling**, this technique provides a powerful and flexible way for models to interface with external systems and access data outside their training data. Function calling give models access to new functionality and data they can use to follow instructions and respond to prompts. As we saw above, the LLM cannot actually execute functions &mdash; the main program listens to the LLM hallucinate, and executes the commands based on that (@fig-brainvat)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07436a08",
   "metadata": {},
   "source": [
    "![(**right**) LLM as brain in a vat that hallucinates outputs from information contained in inputs. It tells us *what* function to execute with *what* arguments. (**left**) The computer listens to the LLM and performs computation based on it.](../img/llm-brain-vat.png){#fig-brainvat width=80%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833803bf",
   "metadata": {},
   "source": [
    "To show tool calling, we find the weather in [Quisao](https://www.philatlas.com/luzon/r04a/rizal/pililla/quisao.html). We want the agent to call the following API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6bdad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2025-08-23T16:15',\n",
       " 'interval': 900,\n",
       " 'temperature_2m': 28.4,\n",
       " 'wind_speed_10m': 2.6,\n",
       " 'relative_humidity_2m': 79,\n",
       " 'precipitation': 0.0,\n",
       " 'precipitation_probability': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"\n",
    "    Get current weather data for provided coordinates with units:\n",
    "    temperature (celsius), wind speed (kph), & precipitation (mm).\n",
    "    \"\"\"\n",
    "    response = requests.get((\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&\"\n",
    "        \"current=temperature_2m,wind_speed_10m,relative_humidity_2m,precipitation,precipitation_probability\"\n",
    "    ))\n",
    "    data = response.json()\n",
    "    return data[\"current\"]\n",
    "\n",
    "\n",
    "get_weather(latitude=14.4779, longitude=121.3214)  # true coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c253083",
   "metadata": {},
   "source": [
    "**Tool definition.** For the LLM to understand a specific tool, we have to define a schema that informs the model of what the tool does and its expected (required and optional) arguments. The following is the function definition for `get_weather`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c9d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\", # <1>\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",  # <2>\n",
    "            \"description\": \"Get current weather data for provided coordinates with units: temperature (celsius), wind speed (kph), & precipitation (mm).\",    # <3>\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", # <4>\n",
    "                \"properties\": { # <5>\n",
    "                    \"latitude\": {\n",
    "                        \"type\": \"number\"\n",
    "                    },\n",
    "                    \"longitude\": {\n",
    "                        \"type\": \"number\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False,  # <6>\n",
    "            },\n",
    "            \"strict\": True, # <7>\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f4811",
   "metadata": {},
   "source": [
    "1. Should always be function.\n",
    "2. Function's name (i.e. `get_weather`).\n",
    "3. Usually just the docstring. Should describe when and how to use the function.\n",
    "4. Parameters for LLMs are naturally JSON objects. Because `parameters` is defined by a JSON schema, you can leverage many of its rich features like property types, enums, descriptions, nested objects, and so on. For example, we can have: \n",
    "    ```\n",
    "    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"unit of measure for temperature\"}\n",
    "    ```\n",
    "5. List of arguments. Clearly the two arguments are required.\n",
    "6. Part of JSON schema that determines whether extra fields are valid or not.\n",
    "7. Not part of JSON schema, but OpenAI function calling option that *guides* the model to strictly follow the schema (i.e. not improvise). Setting `additionalProperties` to `False` and `strict` to `True` works together to ensure that the model generates the correct parameters schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "014a64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'audio': None,\n",
      " 'content': None,\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{\"latitude\":14.4777,\"longitude\":121.3172}',\n",
      "                              'name': 'get_weather'},\n",
      "                 'id': 'call_5HxvMhXUuVUHMnr0ApE5XCQS',\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful weather assistant. Feel free to determine coordinates given location.\"\n",
    "user_prompt = \"What's the weather like in Quisao, Pililla, Rizal right now?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "pprint(completion.choices[0].message.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281f9a4",
   "metadata": {},
   "source": [
    "Impressive that it's able to get fairly accurate coordinates without using web search. Also notice that whenever we have `tools`, then the model only has `tool_calls` as nonempty (e.g. `content` is empty). \n",
    "We will iterate over tool calls and process them separately. Each function call and its result is then logged as part of the sequence of **chat messages** as well as its result. (This explains why we had messages defined outside the API call unlike the usual setup.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f94696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(name, args):\n",
    "    fn = {\n",
    "        \"get_weather\": get_weather  \n",
    "    }\n",
    "    return fn[name](**args)\n",
    "\n",
    "\n",
    "assistant_message = completion.choices[0].message\n",
    "messages.append(assistant_message.model_dump())  # <1>\n",
    "\n",
    "for tool_call in assistant_message.tool_calls:\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    name = tool_call.function.name\n",
    "    tool_output = call_function(name, args)\n",
    "    messages.append({    # <2>\n",
    "        \"role\": \"tool\", \n",
    "        \"tool_call_id\": tool_call.id, \n",
    "        \"content\": json.dumps(tool_output)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14c4e7",
   "metadata": {},
   "source": [
    "1. The tool call is logged with role `assistant`.\n",
    "2. Next, we log the result of the function call with role `tool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc27b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful weather assistant. Feel free to determine '\n",
      "             'coordinates given location.',\n",
      "  'role': 'system'},\n",
      " {'content': \"What's the weather like in Quisao, Pililla, Rizal right now?\",\n",
      "  'role': 'user'},\n",
      " {'annotations': [],\n",
      "  'audio': None,\n",
      "  'content': None,\n",
      "  'function_call': None,\n",
      "  'refusal': None,\n",
      "  'role': 'assistant',\n",
      "  'tool_calls': [{'function': {'arguments': '{\"latitude\":14.4777,\"longitude\":121.3172}',\n",
      "                               'name': 'get_weather'},\n",
      "                  'id': 'call_5HxvMhXUuVUHMnr0ApE5XCQS',\n",
      "                  'type': 'function'}]},\n",
      " {'content': '{\"time\": \"2025-08-23T16:15\", \"interval\": 900, \"temperature_2m\": '\n",
      "             '28.6, \"wind_speed_10m\": 2.6, \"relative_humidity_2m\": 79, '\n",
      "             '\"precipitation\": 0.0, \"precipitation_probability\": 5}',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'call_5HxvMhXUuVUHMnr0ApE5XCQS'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f1dff",
   "metadata": {},
   "source": [
    "Next, we pass this thread to another API call (possibly to a different LLM) which will process the outputs of the tool calls along with earlier chat messages. To take advantage of structured outputs we again define a response format. Here we use Pydantic `Field` with a description that helps the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    response: str = Field(description=\"A natural language response to the user's question.\")\n",
    "    temperature: float = Field(description=\"Current temperature in celsius for the given location.\")\n",
    "\n",
    "\n",
    "completion_weather = client.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,    # <!>\n",
    "    response_format=WeatherResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d568be6",
   "metadata": {},
   "source": [
    ":::{.callout-caution}\n",
    "The aggregator also needs access to tools to understand the context of each tool call!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0fdc2",
   "metadata": {},
   "source": [
    "Final output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52f1eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.6\n",
      "('The current weather in Quisao, Pililla, Rizal is warm with a temperature of '\n",
      " '28.6°C. The wind speed is light at 2.6 kph, and there is no precipitation at '\n",
      " 'the moment, with a low chance of rain.')\n"
     ]
    }
   ],
   "source": [
    "parsed_weather = completion_weather.choices[0].message.parsed\n",
    "print(parsed_weather.temperature)\n",
    "pprint(parsed_weather.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27b1c4",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452795e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
