{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c665168",
   "metadata": {},
   "source": [
    "# Building Effective Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a3b4a",
   "metadata": {},
   "source": [
    "This is based on [this article](https://www.anthropic.com/engineering/building-effective-agents) by [Anthropic](https://www.anthropic.com/). We will explore common patterns for building effective LLM agentic systems using pure Python around LLM APIs. In particular, we use the [Python SDK](https://github.com/openai/openai-python/tree/main) for the [OpenAI API](https://platform.openai.com/docs/api-reference/introduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ab857",
   "metadata": {},
   "source": [
    "## OpenAI API client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339c546",
   "metadata": {},
   "source": [
    "First, we need to load the API key in the environmental variables. The client expects the variable name `OPENAI_API_KEY` which we load from the `.env` file. This is easy to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bfff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def load_dotenv(verbose=False):\n",
      "    with open(\".env\") as f:\n",
      "        for line in f.readlines():\n",
      "            k, v = line.split(\"=\")\n",
      "            os.environ[k] = v.strip().strip('\"')\n",
      "            if verbose:\n",
      "                print(f\"Loaded env variable: {k}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from notebooks.utils import load_dotenv\n",
    "print(inspect.getsource(load_dotenv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d77b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env variable: OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f34dc",
   "metadata": {},
   "source": [
    "Then the API key is automatically read by the **client**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424d6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"You're a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me about the history of GPT in a single paragraph.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_text = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd2ad0",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "We can have **multiple completions** of the same prompt. This allows choosing between the responses.\n",
    "For example, we can set `temperature=0.9` to get more varied outputs, so that choosing becomes nontrivial. \n",
    "By default only 1 completion by default, hence `[0]`.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055bb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generative Pre-trained Transformer (GPT) models, developed by OpenAI, '\n",
      " 'represent significant advancements in natural language processing. The first '\n",
      " 'model, GPT, was released in June 2018, introducing the transformer '\n",
      " 'architecture for generating coherent text based on a given prompt. This was '\n",
      " 'followed by GPT-2 in February 2019, which demonstrated substantial '\n",
      " 'improvements in generating high-quality, contextually relevant text, '\n",
      " 'although its full release was initially withheld due to concerns about '\n",
      " 'misuse. GPT-3, released in June 2020, marked a leap in capability with 175 '\n",
      " 'billion parameters, enabling it to perform a wide range of language tasks '\n",
      " 'with few-shot learning. The series continued with GPT-4, released in March '\n",
      " '2024, offering even more refined capabilities, such as handling even more '\n",
      " 'complex and nuanced tasks. These models have showcased remarkable progress '\n",
      " \"in AI's ability to understand and generate human-like text, influencing \"\n",
      " 'various applications and sparking discussions about ethical considerations '\n",
      " 'in AI deployment.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response_text, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f4a310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generative Pre-trained Transformer (GPT) models, developed by OpenAI, '\n",
      " 'represent significant advancements in natural language processing. The first '\n",
      " 'model, GPT, was released in June 2018, introducing the transformer '\n",
      " 'architecture for generating coherent text based on a given prompt. This was '\n",
      " 'followed by GPT-2 in February 2019, which demonstrated substantial '\n",
      " 'improvements in generating high-quality, contextually relevant text, '\n",
      " 'although its full release was initially withheld due to concerns about '\n",
      " 'misuse. GPT-3, released in June 2020, marked a leap in capability with 175 '\n",
      " 'billion parameters, enabling it to perform a wide range of language tasks '\n",
      " 'with few-shot learning. The series continued with GPT-4, released in March '\n",
      " '2024, offering even more refined capabilities, such as handling even more '\n",
      " 'complex and nuanced tasks. These models have showcased remarkable progress '\n",
      " \"in AI's ability to understand and generate human-like text, influencing \"\n",
      " 'various applications and sparking discussions about ethical considerations '\n",
      " 'in AI deployment.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda6e7b",
   "metadata": {},
   "source": [
    "Entire model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55f61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'annotations': [],\n",
      "                          'audio': None,\n",
      "                          'content': 'Generative Pre-trained Transformer (GPT) '\n",
      "                                     'models, developed by OpenAI, represent '\n",
      "                                     'significant advancements in natural '\n",
      "                                     'language processing. The first model, '\n",
      "                                     'GPT, was released in June 2018, '\n",
      "                                     'introducing the transformer architecture '\n",
      "                                     'for generating coherent text based on a '\n",
      "                                     'given prompt. This was followed by GPT-2 '\n",
      "                                     'in February 2019, which demonstrated '\n",
      "                                     'substantial improvements in generating '\n",
      "                                     'high-quality, contextually relevant '\n",
      "                                     'text, although its full release was '\n",
      "                                     'initially withheld due to concerns about '\n",
      "                                     'misuse. GPT-3, released in June 2020, '\n",
      "                                     'marked a leap in capability with 175 '\n",
      "                                     'billion parameters, enabling it to '\n",
      "                                     'perform a wide range of language tasks '\n",
      "                                     'with few-shot learning. The series '\n",
      "                                     'continued with GPT-4, released in March '\n",
      "                                     '2024, offering even more refined '\n",
      "                                     'capabilities, such as handling even more '\n",
      "                                     'complex and nuanced tasks. These models '\n",
      "                                     'have showcased remarkable progress in '\n",
      "                                     \"AI's ability to understand and generate \"\n",
      "                                     'human-like text, influencing various '\n",
      "                                     'applications and sparking discussions '\n",
      "                                     'about ethical considerations in AI '\n",
      "                                     'deployment.',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None}}],\n",
      " 'created': 1756152277,\n",
      " 'id': 'chatcmpl-C8XifZcOeErXmwvSx8mKz3jDTfMBG',\n",
      " 'model': 'gpt-4o-2024-08-06',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_80956533cb',\n",
      " 'usage': {'completion_tokens': 191,\n",
      "           'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
      "                                         'audio_tokens': 0,\n",
      "                                         'reasoning_tokens': 0,\n",
      "                                         'rejected_prediction_tokens': 0},\n",
      "           'prompt_tokens': 28,\n",
      "           'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0},\n",
      "           'total_tokens': 219}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(completion.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff814f09",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "We are using the **chat completions** API where an autoregressive process that's running under the hood. Here the prompt to be completed is:\n",
    "\n",
    "```python\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic but terse assistant.\"},   # prompt\n",
    "    {\"role\": \"user\", \"content\": \"What is the color of the sky?\"}              # prompt\n",
    "]\n",
    "```\n",
    "\n",
    "And the completion is given by the API's output:\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"content\": \"The sky's color shifts from azure to amber, a canvas for sun's daily journey.\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Remark.** The generated response is statistically the most likely continuation of the prompt text sequence. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2c766d",
   "metadata": {},
   "source": [
    "## Structured outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52597344",
   "metadata": {},
   "source": [
    "[Structured outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses) is a feature that ensures that a model generates responses that adhere to a supplied **schema** (e.g. a Pydantic model). As such, the output can then be parsed using the same Pydantic model. Structured outputs makes prompting significantly simpler: no more need for strongly worded prompts to achieve consistent formatting, no explicitly having to retry incorrectly formatted responses, or having invalid hallucinated values (can specify **enums**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70811ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "completion = client.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    response_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "event = completion.choices[0].message.parsed\n",
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc0da2",
   "metadata": {},
   "source": [
    "## Building block: Augmented LLM\n",
    "\n",
    "This is the foundational building block of agentic systems. The **augmented LLM** is a language model enhanced with **retrieval**, **tools**, and **memory**. Current models, due to their reasoning and understanding capabilities, are able to effectively generate their own search queries, select appropriate tools, and determinine what information in necessary to retain or retrieve to solve problems or perform tasks. Augmentation is necessary for LLMs to reason about data outside of their training data, or data that is outdated relative to the training cutoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb22b7f",
   "metadata": {},
   "source": [
    "![**The augmented LLM.** A conceptual diagram of a core LLM service augmented with retrieval, tools, and memory capabilities.](../img/augmented-llm.png){#fig-augmentedllm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98448acb",
   "metadata": {},
   "source": [
    "### Tool calling\n",
    "\n",
    "Also known as **function calling**. Function calling give models access to external tools and data that they can use to respond to prompts. Since LLMs *only* consume and generate text, they cannot actually execute functions. Instead, the main program listens to the LLM hallucinate and executes the commands based on that (@fig-brainvat)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07436a08",
   "metadata": {},
   "source": [
    "![(**right**) LLM as brain in a vat that hallucinates outputs from information contained in inputs. It tells us *what* function to execute with *what* arguments. (**left**) The computer listens to the LLM and performs computation based on it.](../img/llm-brain-vat.png){#fig-brainvat width=80%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833803bf",
   "metadata": {},
   "source": [
    "To show tool calling, we find the weather in [Quisao](https://www.philatlas.com/luzon/r04a/rizal/pililla/quisao.html). We want the agent to call the following API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6bdad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2025-08-25T20:00',\n",
       " 'interval': 900,\n",
       " 'temperature_2m': 26.0,\n",
       " 'wind_speed_10m': 3.9,\n",
       " 'relative_humidity_2m': 93,\n",
       " 'precipitation': 0.4,\n",
       " 'precipitation_probability': 75}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"\n",
    "    Get current weather data for provided coordinates with units:\n",
    "    temperature (celsius), wind speed (kph), & precipitation (mm).\n",
    "    \"\"\"\n",
    "    response = requests.get((\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&\"\n",
    "        \"current=temperature_2m,wind_speed_10m,relative_humidity_2m,precipitation,precipitation_probability\"\n",
    "    ))\n",
    "    data = response.json()\n",
    "    return data[\"current\"]\n",
    "\n",
    "\n",
    "get_weather(latitude=14.4779, longitude=121.3214)  # true coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c253083",
   "metadata": {},
   "source": [
    "**Tool definition.** For the LLM to understand a specific tool, we have to define a schema that informs the model of what the tool does and its expected (required and optional) arguments. The following is the function definition for `get_weather`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8c9d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\", # <1>\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",  # <2>\n",
    "            \"description\": \"Get current weather data for provided coordinates with units: temperature (celsius), wind speed (kph), & precipitation (mm).\",    # <3>\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\", # <4>\n",
    "                \"properties\": { # <5>\n",
    "                    \"latitude\": {\n",
    "                        \"type\": \"number\"\n",
    "                    },\n",
    "                    \"longitude\": {\n",
    "                        \"type\": \"number\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"],\n",
    "                \"additionalProperties\": False,  # <6>\n",
    "            },\n",
    "            \"strict\": True, # <7>\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f4811",
   "metadata": {},
   "source": [
    "1. Should always be function.\n",
    "2. Function's name (i.e. `get_weather`).\n",
    "3. Usually just the docstring. Should describe when and how to use the function.\n",
    "4. Parameters for LLMs are naturally JSON objects. Because `parameters` is defined by a JSON schema, you can leverage many of its rich features like property types, enums, descriptions, nested objects, and so on. For example, we can have: \n",
    "    ```\n",
    "    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"unit of measure for temperature\"}\n",
    "    ```\n",
    "5. List of arguments. Clearly the two arguments are required.\n",
    "6. Part of JSON schema that determines whether extra fields are valid or not.\n",
    "7. Not part of JSON schema, but OpenAI function calling option that *guides* the model to strictly follow the schema (i.e. not improvise). Setting `additionalProperties` to `False` and `strict` to `True` works together to ensure that the model generates the correct parameters schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "014a64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': [],\n",
      " 'audio': None,\n",
      " 'content': None,\n",
      " 'function_call': None,\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{\"latitude\":14.4952,\"longitude\":121.3581}',\n",
      "                              'name': 'get_weather'},\n",
      "                 'id': 'call_jhGLTL9Kyhty8QKlujOgnwxm',\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful weather assistant.\"\n",
    "user_prompt = \"What's the weather like in Quisao, Pililla, Rizal right now?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "pprint(completion.choices[0].message.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281f9a4",
   "metadata": {},
   "source": [
    "Impressive that it's able to get fairly accurate coordinates without using web search. Also notice that whenever we have `tools`, the model responds with only `tool_calls` as nonempty (e.g. `content` is empty). \n",
    "We will iterate over tool calls and process them separately. Each function call and their results are then logged as part of the sequence of **chat messages**. This explains why we defined `messages` outside of the API call unlike the usual setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94696d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(name, args):\n",
    "    fn = {\n",
    "        \"get_weather\": get_weather  \n",
    "    }\n",
    "    return fn[name](**args)\n",
    "\n",
    "\n",
    "assistant_message = completion.choices[0].message\n",
    "messages.append(assistant_message.model_dump())  # <1>\n",
    "\n",
    "for tool_call in assistant_message.tool_calls:\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    name = tool_call.function.name\n",
    "    tool_output = call_function(name, args)\n",
    "    messages.append({    # <2>\n",
    "        \"role\": \"tool\", \n",
    "        \"tool_call_id\": tool_call.id, \n",
    "        \"content\": json.dumps(tool_output)\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d14c4e7",
   "metadata": {},
   "source": [
    "1. The tool call is logged with role `assistant`.\n",
    "2. Next, we log the result of the function call with role `tool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cc27b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful weather assistant.', 'role': 'system'},\n",
      " {'content': \"What's the weather like in Quisao, Pililla, Rizal right now?\",\n",
      "  'role': 'user'},\n",
      " {'annotations': [],\n",
      "  'audio': None,\n",
      "  'content': None,\n",
      "  'function_call': None,\n",
      "  'refusal': None,\n",
      "  'role': 'assistant',\n",
      "  'tool_calls': [{'function': {'arguments': '{\"latitude\":14.4952,\"longitude\":121.3581}',\n",
      "                               'name': 'get_weather'},\n",
      "                  'id': 'call_jhGLTL9Kyhty8QKlujOgnwxm',\n",
      "                  'type': 'function'}]},\n",
      " {'content': '{\"time\": \"2025-08-25T20:00\", \"interval\": 900, \"temperature_2m\": '\n",
      "             '25.0, \"wind_speed_10m\": 1.3, \"relative_humidity_2m\": 93, '\n",
      "             '\"precipitation\": 0.3, \"precipitation_probability\": 90}',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'call_jhGLTL9Kyhty8QKlujOgnwxm'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af390cce",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "Chat completion API calls have stateless single request-response cycles which gives the user straightforward control over the **message history**. This can be seen in the above example where we manually manage message history with tool calls declaration as well as actual function outputs.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f1dff",
   "metadata": {},
   "source": [
    "Next, we pass this thread to another API call (possibly to a different LLM) which will process the outputs of the tool calls along with earlier chat messages. To take advantage of structured outputs we again define a response format. Here we use Pydantic `Field` with a description that helps the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e9bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field\n",
    "\n",
    "class WeatherResponse(BaseModel):\n",
    "    response: str = Field(description=\"A natural language response to the user's question.\")\n",
    "    temperature: float = Field(description=\"Current temperature in celsius for the given location.\")\n",
    "\n",
    "\n",
    "completion_weather = client.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,    # <!>\n",
    "    response_format=WeatherResponse,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d568be6",
   "metadata": {},
   "source": [
    ":::{.callout-caution}\n",
    "The aggregator also needs access to tools for it to understand the context of each tool call!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e0fdc2",
   "metadata": {},
   "source": [
    "**Final output.** Note that even units (included in the `get_weather` docstring) were correctly identified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f1eda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n",
      "('Currently, in Quisao, Pililla, Rizal, it is 25Â°C with a light wind speed of '\n",
      " '1.3 kph. The air is very humid with a relative humidity of 93%, and there is '\n",
      " 'a high chance of precipitation at 0.3 mm of rain.')\n"
     ]
    }
   ],
   "source": [
    "parsed_weather = completion_weather.choices[0].message.parsed\n",
    "print(parsed_weather.temperature)\n",
    "pprint(parsed_weather.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27b1c4",
   "metadata": {},
   "source": [
    "### Memory and retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76762d",
   "metadata": {},
   "source": [
    "The following is a toy example of an agent that reads and writes to an external data source. One characteristic of retrieval systems is that the entire process is **stateless**, e.g. it cannot learn from interactions. Retrieval systems generally involve queries to an external data source, then adding the response to the current model context.\n",
    "\n",
    "For the following example, the LLM also writes to the same memory store hence affecting future generation states. Hence, it is **stateful**. We can think of the external memory store as the **long-term memory** of the system. On the other hand, LLMs naturally have **short-term memory** in the form of its context. The architecture is shown in @fig-retrieval-system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd8b60",
   "metadata": {},
   "source": [
    "![The LLM expresses the intent to write to the memory store via the structured output. Then, it is up to the main program to perform the actual writing. This allows hooks like [guardrails](https://cookbook.openai.com/examples/how_to_use_guardrails) to be applied before executing the function. Note that the retrieval happens prior to LLM processing. It would be nice to have the LLM read the entire filestore but this becomes more expensive as the memory store grows. In practice, information retrieval techniques such as TF-IDF and embedding similarity can be used.\n",
    "](../img/retrieval-system.png){#fig-retrieval-system}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ada622",
   "metadata": {},
   "source": [
    "Below, we do keyword search in the retrieval step. So we define a function for removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d4ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Punk is a pre-trained unsupervised machine learning model for tokenization. It's one of the most crucial and widely used components in the NLTK library.\n",
      "Filtered: ['punk', 'pre-trained', 'unsupervised', 'machine', 'learning', 'model', 'tokenization', \"'s\", 'one', 'crucial', 'widely', 'used', 'components', 'nltk', 'library']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"Tokenize into words then remove stopwords.\"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words and word not in string.punctuation]\n",
    "    return filtered_tokens\n",
    "\n",
    "text = \"Punk is a pre-trained unsupervised machine learning model for tokenization. It's one of the most crucial and widely used components in the NLTK library.\"\n",
    "print(\"Original:\", text)\n",
    "print(\"Filtered:\", tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e31d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class MemoryItem(BaseModel):\n",
    "    tag: str\n",
    "    info: str\n",
    "    reason: str\n",
    "\n",
    "class RetainResponse(BaseModel):\n",
    "    items: List[MemoryItem]\n",
    "\n",
    "\n",
    "class MemoryStore:\n",
    "    def __init__(self, path=\"memory.json\"):\n",
    "        \"\"\"Load memory from JSON file in local path.\"\"\"\n",
    "        self.path = path\n",
    "        self.data = []\n",
    "        self.tags = set()\n",
    "        self.load()\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            self.data = json.load(open(self.path))\n",
    "        except FileNotFoundError:\n",
    "            self.reset()\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.path, \"w\") as f:\n",
    "            json.dump(self.data, f, indent=2)\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = []\n",
    "        self.tags = set()\n",
    "        self.save()\n",
    "    \n",
    "    def add(self, item: MemoryItem):\n",
    "        tag, info = item.tag, item.info\n",
    "        self.tags.add(tag)\n",
    "        self.data.append({\"tag\": tag, \"info\": info})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def retrieve(self, query: str, topk: int = 3) -> List[dict]:\n",
    "        \"\"\"Simple keyword-based retrieval.\"\"\"\n",
    "        \n",
    "        query_words = tokenize(query)\n",
    "        retrieved = []\n",
    "        \n",
    "        for memory in reversed(self.data):  # <1>\n",
    "            tag, info = memory[\"tag\"], memory[\"info\"]\n",
    "            info = ' '.join(tokenize(info))\n",
    "            memory_text = f\"{tag} {info}\".lower()\n",
    "\n",
    "            for word in query_words:\n",
    "                if word in memory_text: # <2>\n",
    "                    retrieved.append(memory)\n",
    "                    break\n",
    "            \n",
    "            if len(retrieved) == topk:\n",
    "                break\n",
    "        \n",
    "        return retrieved\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "mem = MemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68e9d4",
   "metadata": {},
   "source": [
    "1. More recent = more relevant.\n",
    "2. Substring check. e.g. `'commute' in 'commute_experience'` evaluates to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923cc4dd",
   "metadata": {},
   "source": [
    "Next, we define the **LLM generation step** and **write step**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78de9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_generate(user_input, topk: int = 3):\n",
    "    \"\"\"Generate memory items from current input and existing memory.\"\"\"\n",
    "\n",
    "    retrieved_memories = mem.retrieve(user_input, topk)\n",
    "    current_tags = list(mem.tags)\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "You are an assistant that logs daily interactions. \n",
    "Relevant past memories based on your current input:\n",
    "{retrieved_memories}\n",
    "\n",
    "Current tags:\n",
    "{current_tags}\n",
    "\n",
    "Your goal is to identify and retain atomic, standalone facts \n",
    "that are likely to be relevant for future interactions.\n",
    "\n",
    "**GUIDELINES:**\n",
    "\n",
    "1. **EXTRACT ATOMIC FACTS:**\n",
    "    - Break down information into the smallest meaningful, self-contained units.\n",
    "    - **Good**: \"User's favorite programmer is Jon Blow.\"\n",
    "    - **Bad**: \"User mentioned their favorite programmer is Jon Blow who is a famous game programmer\" (This has two facts.)\n",
    "    - The `info` must be a concise, direct paraphrase of the fact. Remove conversational fluff.\n",
    "    - **Good Info:** \"User's favorite city is Tokyo\"\n",
    "    - **Bad Info:** \"The user stated that if they had to pick a favorite city, they think it would be Tokyo.\"\n",
    "\n",
    "2.  **TAG EFFECTIVELY:**\n",
    "    - **Format:** Prefer generic, descriptive tags in `snake_case`.\n",
    "    - **Simple:** Prefer simple tags. Choose `commute` is better than `commute_experience`.\n",
    "    - **Reuse:** Strongly prefer existing tags. Create a new tag only if necessary.\n",
    "    - An example: For \"I really enjoy hiking in the Alps every summer,\" a good tag is `hobby` or `outdoor_activity`.\n",
    "    \n",
    "4.  **EVALUATE & DECIDE:**\n",
    "    - It is acceptable to save zero logs from an input if nothing is meaningfully new or relevant.\n",
    "    - Save multiple logs if the user provides multiple distinct pieces of information.\n",
    "    - Each memory item should make sense on its own. There should be no dependence between separate logs.\n",
    "\"\"\"\n",
    "    \n",
    "    completion = client.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=RetainResponse,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.parsed\n",
    "\n",
    "\n",
    "def write(user_input: str) -> RetainResponse:\n",
    "    \"\"\"Write generated items to memory store.\"\"\"\n",
    "    response = llm_generate(user_input)\n",
    "    for item in response.items:\n",
    "        mem.add(item)\n",
    "    \n",
    "    mem.save()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce0933b",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6599b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logs = [\n",
    "    \"Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.\",\n",
    "    \"Traffic was smooth, arrived at work earlier than usual.\",\n",
    "    \"Took the train, had to stand the whole ride since it was packed.\",\n",
    "    \"Stopped by the bakery on the way and picked up bread for the team.\",\n",
    "    \"Opened my email first thing at the office, mostly routine messages.\",\n",
    "    \"Woah! Some guy just came out of nowhere and darted into traffic. That was pretty shocking. Crazy.\",\n",
    "    \"Listened to a podcast while walking to the subway.\",\n",
    "    \"Grabbed a pen from my desk drawer because mine ran out of ink.\",\n",
    "]\n",
    "\n",
    "items = []\n",
    "for input_text in logs:\n",
    "    for item in write(input_text).items:\n",
    "        d = item.model_dump()\n",
    "        d[\"text\"] = input_text\n",
    "        items.append(d)\n",
    "\n",
    "df_resp = pd.DataFrame(items)\n",
    "mem.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b4ef6",
   "metadata": {},
   "source": [
    "The agent decides whether to reuse a tag or create a new one based on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d4931a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags: (8 total logs, 4 tags, 9 saved)\n",
      "['morning_routine', 'breakfast', 'commute', 'office_supplies']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morning_routine</td>\n",
       "      <td>User usually wakes up, showers, and leaves for work at the same time.</td>\n",
       "      <td>The routine of waking, showering, and leaving at the same time suggests a patterned behavior, which could be relevant for scheduling future interactions.</td>\n",
       "      <td>Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breakfast</td>\n",
       "      <td>User had toast for breakfast.</td>\n",
       "      <td>What someone eats for breakfast can reveal dietary habits or preferences.</td>\n",
       "      <td>Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commute</td>\n",
       "      <td>Traffic was smooth, user arrived at work earlier than usual.</td>\n",
       "      <td>This logs tidbits about the user's commute which could be relevant for understanding their routine and any variance such as a change of arrival time.</td>\n",
       "      <td>Traffic was smooth, arrived at work earlier than usual.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>commute</td>\n",
       "      <td>User took a crowded train and stood the entire ride.</td>\n",
       "      <td>This provides information about the user's commuting experience, which could be relevant for future transportation or schedule discussions.</td>\n",
       "      <td>Took the train, had to stand the whole ride since it was packed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morning_routine</td>\n",
       "      <td>User stopped by the bakery to pick up bread for the team.</td>\n",
       "      <td>This is a specific action within the user's morning routine that could be relevant in discussing commuting habits or team interactions.</td>\n",
       "      <td>Stopped by the bakery on the way and picked up bread for the team.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>morning_routine</td>\n",
       "      <td>User opens their email first thing at the office.</td>\n",
       "      <td>This is a specific action performed regularly as part of the user's work routine.</td>\n",
       "      <td>Opened my email first thing at the office, mostly routine messages.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>commute</td>\n",
       "      <td>A pedestrian unexpectedly ran into traffic, shocking the user.</td>\n",
       "      <td>This is a distinct event related to the user's commute experiencing something unusual.</td>\n",
       "      <td>Woah! Some guy just came out of nowhere and darted into traffic. That was pretty shocking. Crazy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>commute</td>\n",
       "      <td>User listened to a podcast while walking to the subway.</td>\n",
       "      <td>This fact about the user's commute routine might be relevant for future interactions, especially those relating to how they spend their commute time.</td>\n",
       "      <td>Listened to a podcast while walking to the subway.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>office_supplies</td>\n",
       "      <td>User keeps pens in their desk drawer.</td>\n",
       "      <td>This fact about where the user stores their pens could be relevant for future interactions about office supplies or organizational habits.</td>\n",
       "      <td>Grabbed a pen from my desk drawer because mine ran out of ink.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tag  \\\n",
       "0  morning_routine   \n",
       "1        breakfast   \n",
       "2          commute   \n",
       "3          commute   \n",
       "4  morning_routine   \n",
       "5  morning_routine   \n",
       "6          commute   \n",
       "7          commute   \n",
       "8  office_supplies   \n",
       "\n",
       "                                                                    info  \\\n",
       "0  User usually wakes up, showers, and leaves for work at the same time.   \n",
       "1                                          User had toast for breakfast.   \n",
       "2           Traffic was smooth, user arrived at work earlier than usual.   \n",
       "3                   User took a crowded train and stood the entire ride.   \n",
       "4              User stopped by the bakery to pick up bread for the team.   \n",
       "5                      User opens their email first thing at the office.   \n",
       "6         A pedestrian unexpectedly ran into traffic, shocking the user.   \n",
       "7                User listened to a podcast while walking to the subway.   \n",
       "8                                  User keeps pens in their desk drawer.   \n",
       "\n",
       "                                                                                                                                                      reason  \\\n",
       "0  The routine of waking, showering, and leaving at the same time suggests a patterned behavior, which could be relevant for scheduling future interactions.   \n",
       "1                                                                                  What someone eats for breakfast can reveal dietary habits or preferences.   \n",
       "2      This logs tidbits about the user's commute which could be relevant for understanding their routine and any variance such as a change of arrival time.   \n",
       "3                This provides information about the user's commuting experience, which could be relevant for future transportation or schedule discussions.   \n",
       "4                    This is a specific action within the user's morning routine that could be relevant in discussing commuting habits or team interactions.   \n",
       "5                                                                          This is a specific action performed regularly as part of the user's work routine.   \n",
       "6                                                                     This is a distinct event related to the user's commute experiencing something unusual.   \n",
       "7      This fact about the user's commute routine might be relevant for future interactions, especially those relating to how they spend their commute time.   \n",
       "8                 This fact about where the user stores their pens could be relevant for future interactions about office supplies or organizational habits.   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.  \n",
       "1  Woke up, showered, and left for work at the usual time. Had toast for breakfast before heading out.  \n",
       "2                                              Traffic was smooth, arrived at work earlier than usual.  \n",
       "3                                     Took the train, had to stand the whole ride since it was packed.  \n",
       "4                                   Stopped by the bakery on the way and picked up bread for the team.  \n",
       "5                                  Opened my email first thing at the office, mostly routine messages.  \n",
       "6    Woah! Some guy just came out of nowhere and darted into traffic. That was pretty shocking. Crazy.  \n",
       "7                                                   Listened to a podcast while walking to the subway.  \n",
       "8                                       Grabbed a pen from my desk drawer because mine ran out of ink.  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(\"tags:\", f\"({len(logs)} total logs, {len(df_resp.tag.unique())} tags, {len(df_resp)} saved)\")\n",
    "pprint(list(df_resp.tag.unique()))\n",
    "df_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec029b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
