{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c665168",
   "metadata": {},
   "source": [
    "# Building Effective Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a3b4a",
   "metadata": {},
   "source": [
    "This is based on [this article](https://www.anthropic.com/engineering/building-effective-agents) by [Anthropic](https://www.anthropic.com/). We will explore common patterns for building effective LLM agentic systems using pure Python around LLM APIs. In particular, we use the [Python SDK](https://github.com/openai/openai-python/tree/main) for the [OpenAI API](https://platform.openai.com/docs/api-reference/introduction). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ab857",
   "metadata": {},
   "source": [
    "## OpenAI API client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339c546",
   "metadata": {},
   "source": [
    "First, we need to load the API key in the environmental variables. The client expects the variable name `OPENAI_API_KEY` which we load from the `.env` file. This is easy to implement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5bfff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def load_dotenv(verbose=False):\n",
      "    with open(\".env\") as f:\n",
      "        for line in f.readlines():\n",
      "            k, v = line.split(\"=\")\n",
      "            os.environ[k] = v.strip().strip('\"')\n",
      "            if verbose:\n",
      "                print(f\"Loaded env variable: {k}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from notebooks.utils import load_dotenv\n",
    "print(inspect.getsource(load_dotenv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d77b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded env variable: OPENAI_API_KEY\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14f34dc",
   "metadata": {},
   "source": [
    "Then the API key is automatically read by the **client**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d6f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4.1\",\n",
    "  input=\"Tell me a three sentence bedtime story about a unicorn.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e4ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luna the unicorn loved to gallop beneath the shimmering stars, her silver horn\n",
      "glowing softly in the moonlight. One magical night, she discovered a hidden\n",
      "grove where fireflies danced and flowers sang lullabies just for her. As she\n",
      "curled up to rest, the peaceful melodies wrapped around her like a cozy blanket,\n",
      "carrying her into the sweetest dreams.\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "import textwrap\n",
    "text = response.output[0].content[0].text\n",
    "wrapped_lines = textwrap.wrap(text, width=80)\n",
    "[print(line) for line in wrapped_lines];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda6e7b",
   "metadata": {},
   "source": [
    "Entire model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'background': False,\n",
      " 'conversation': None,\n",
      " 'created_at': 1755889803.0,\n",
      " 'error': None,\n",
      " 'id': 'resp_68a8c08bac0881a1bc692232f86ac58407baeab058dc36b4',\n",
      " 'incomplete_details': None,\n",
      " 'instructions': None,\n",
      " 'max_output_tokens': None,\n",
      " 'max_tool_calls': None,\n",
      " 'metadata': {},\n",
      " 'model': 'gpt-4.1-2025-04-14',\n",
      " 'object': 'response',\n",
      " 'output': [{'content': [{'annotations': [],\n",
      "                          'logprobs': [],\n",
      "                          'text': 'Luna the unicorn loved to gallop beneath '\n",
      "                                  'the shimmering stars, her silver horn '\n",
      "                                  'glowing softly in the moonlight. One '\n",
      "                                  'magical night, she discovered a hidden '\n",
      "                                  'grove where fireflies danced and flowers '\n",
      "                                  'sang lullabies just for her. As she curled '\n",
      "                                  'up to rest, the peaceful melodies wrapped '\n",
      "                                  'around her like a cozy blanket, carrying '\n",
      "                                  'her into the sweetest dreams.',\n",
      "                          'type': 'output_text'}],\n",
      "             'id': 'msg_68a8c08bfcf881a1a26fe3b6c18a27d507baeab058dc36b4',\n",
      "             'role': 'assistant',\n",
      "             'status': 'completed',\n",
      "             'type': 'message'}],\n",
      " 'parallel_tool_calls': True,\n",
      " 'previous_response_id': None,\n",
      " 'prompt': None,\n",
      " 'prompt_cache_key': None,\n",
      " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
      " 'safety_identifier': None,\n",
      " 'service_tier': 'default',\n",
      " 'status': 'completed',\n",
      " 'store': True,\n",
      " 'temperature': 1.0,\n",
      " 'text': {'format': {'type': 'text'}, 'verbosity': 'medium'},\n",
      " 'tool_choice': 'auto',\n",
      " 'tools': [],\n",
      " 'top_logprobs': 0,\n",
      " 'top_p': 1.0,\n",
      " 'truncation': 'disabled',\n",
      " 'usage': {'input_tokens': 18,\n",
      "           'input_tokens_details': {'cached_tokens': 0},\n",
      "           'output_tokens': 71,\n",
      "           'output_tokens_details': {'reasoning_tokens': 0},\n",
      "           'total_tokens': 89},\n",
      " 'user': None}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc0da2",
   "metadata": {},
   "source": [
    "## Building block: The augmented LLM\n",
    "\n",
    "This is the foundational building block of agentic systems. The **augmented LLM** is a language model enhanced with **retrieval**, **tools**, and **memory**. Current models, due to their reasoning and understanding capabilities, are able to effectively generate their own search queries, select appropriate tools, and determinine what information to retain to solve problems or perform tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d73ec",
   "metadata": {},
   "source": [
    "![Augmented LLM](../img/augmented-llm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class RetainResponse(BaseModel):\n",
    "    retain: bool\n",
    "    key: str\n",
    "    value: str\n",
    "    reason: str\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "memory_file = \"agent_memory.json\"\n",
    "\n",
    "def load_memory():\n",
    "    try:\n",
    "        return json.load(open(memory_file))\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "    \n",
    "def reset_memory():\n",
    "    with open(memory_file, \"w\") as f:\n",
    "        json.dump({}, f, indent=2)\n",
    "\n",
    "def save_memory(memory):\n",
    "    with open(memory_file, \"w\") as f:\n",
    "        json.dump(memory, f, indent=2)\n",
    "\n",
    "def agent(user_input):\n",
    "    memory = load_memory()\n",
    "    system_prompt = (\n",
    "        f\"You have access to a memory store: {memory}. \"\n",
    "        \"Decide what new information should be remembered. \"\n",
    "        \"NOTE: The key for a given value should be fairly generic.\"\n",
    "    )\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=RetainResponse,\n",
    "    )\n",
    "\n",
    "    response = completion.choices[0].message.parsed\n",
    "    return response\n",
    "\n",
    "\n",
    "def action(user_input: str):\n",
    "    response = agent(user_input)\n",
    "    if response.retain:\n",
    "        memory = load_memory()\n",
    "        values = set(memory.get(response.key, []))\n",
    "        values.add(response.value)\n",
    "        memory[response.key] = list(values)\n",
    "        save_memory(memory)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb83cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [\n",
    "    \"Hi, my name is Ron. Please remember that.\",\n",
    "    \"I'm Doug. I use this application frequently.\",\n",
    "    \"My name's Joe. I'm a temporary user.\",\n",
    "    \"I'm Q. I used the app today.\",\n",
    "    \"My name's Karen. I don't want any of my information in your systems.\"\n",
    "]\n",
    "\n",
    "df_resp = pd.DataFrame([action(text).model_dump() for text in inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8cc5f",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71df11e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>retain</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_name⠀⠀⠀⠀⠀</td>\n",
       "      <td>Ron⠀⠀⠀⠀⠀⠀⠀⠀</td>\n",
       "      <td>True⠀⠀⠀⠀</td>\n",
       "      <td>Knowing the user's name helps personalize interactions in future conversations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_name</td>\n",
       "      <td>Doug</td>\n",
       "      <td>True</td>\n",
       "      <td>The user identified themselves as Doug and mentioned frequent usage of the application, which implies that remembering this information would enhance user interaction and personalization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_name</td>\n",
       "      <td>Joe</td>\n",
       "      <td>False</td>\n",
       "      <td>Since the user has indicated that they are a temporary user, it might not be necessary to retain their name for long-term purposes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_name</td>\n",
       "      <td>Q</td>\n",
       "      <td>True</td>\n",
       "      <td>A new user's name has been introduced and should be retained in the memory store for future reference.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_name</td>\n",
       "      <td>Karen</td>\n",
       "      <td>False</td>\n",
       "      <td>The user explicitly requested not to have their information stored in the system.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              key        value    retain  \\\n",
       "0  user_name⠀⠀⠀⠀⠀  Ron⠀⠀⠀⠀⠀⠀⠀⠀  True⠀⠀⠀⠀   \n",
       "1       user_name         Doug      True   \n",
       "2       user_name          Joe     False   \n",
       "3       user_name            Q      True   \n",
       "4       user_name        Karen     False   \n",
       "\n",
       "                                                                                                                                                                                        reason  \n",
       "0                                                                                                              Knowing the user's name helps personalize interactions in future conversations.  \n",
       "1  The user identified themselves as Doug and mentioned frequent usage of the application, which implies that remembering this information would enhance user interaction and personalization.  \n",
       "2                                                          Since the user has indicated that they are a temporary user, it might not be necessary to retain their name for long-term purposes.  \n",
       "3                                                                                       A new user's name has been introduced and should be retained in the memory store for future reference.  \n",
       "4                                                                                                            The user explicitly requested not to have their information stored in the system.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_resp.loc[0, \"retain\"] = \"True⠀⠀⠀⠀⠀\" if df_resp.loc[0, \"retain\"] else \"False⠀⠀⠀⠀⠀\"\n",
    "df_resp.loc[0, \"value\"] = df_resp.loc[0, \"value\"] + \"⠀⠀⠀⠀⠀\"\n",
    "df_resp.loc[0, \"key\"]   = df_resp.loc[0, \"key\"] + \"⠀⠀⠀⠀\"\n",
    "df_resp[[\"key\", \"value\", \"retain\", \"reason\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fd83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_name': ['Doug', 'Q', 'Ron']}\n"
     ]
    }
   ],
   "source": [
    "print(load_memory())\n",
    "reset_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98448acb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
